{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce5fa158",
   "metadata": {},
   "source": [
    "# Deep Learning 1\n",
    "We will provide a detailed explanation based on the handwritten digit recognition program introduced on the second lecture.\n",
    "First, let's present the handwritten digit recognition program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb48ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 1, Loss:2.299196720123291\n",
      "1, 100, Loss:1.503427717089653\n",
      "1, 200, Loss:0.9781293166428804\n",
      "1, 300, Loss:0.7688145390152932\n",
      "1, 400, Loss:0.6506744086369872\n",
      "1, 500, Loss:0.5764600720852614\n",
      "1, 600, Loss:0.5216090929880738\n",
      "Total loss:0.5216090929880738\n",
      "2, 1, Loss:0.2686532735824585\n",
      "2, 100, Loss:0.22512469820678235\n",
      "2, 200, Loss:0.2149828828126192\n",
      "2, 300, Loss:0.20465209330121675\n",
      "2, 400, Loss:0.1972691385820508\n",
      "2, 500, Loss:0.18863634123653172\n",
      "2, 600, Loss:0.1826807174521188\n",
      "Total loss:0.1826807174521188\n",
      "3, 1, Loss:0.0929945632815361\n",
      "3, 100, Loss:0.1276093866676092\n",
      "3, 200, Loss:0.1263842006586492\n",
      "3, 300, Loss:0.12236206198732058\n",
      "3, 400, Loss:0.11847318078391254\n",
      "3, 500, Loss:0.11574019915610552\n",
      "3, 600, Loss:0.11186994348652661\n",
      "Total loss:0.11186994348652661\n",
      "4, 1, Loss:0.11827472597360611\n",
      "4, 100, Loss:0.08581236591562628\n",
      "4, 200, Loss:0.08788658922538162\n",
      "4, 300, Loss:0.08460415255899231\n",
      "4, 400, Loss:0.08205918801715598\n",
      "4, 500, Loss:0.0811321620810777\n",
      "4, 600, Loss:0.07944747865200043\n",
      "Total loss:0.07944747865200043\n",
      "5, 1, Loss:0.1212952509522438\n",
      "5, 100, Loss:0.06610834250226617\n",
      "5, 200, Loss:0.06648922940250486\n",
      "5, 300, Loss:0.06491685778213044\n",
      "5, 400, Loss:0.06361883877776563\n",
      "5, 500, Loss:0.06278244279697537\n",
      "5, 600, Loss:0.06213864701644828\n",
      "Total loss:0.06213864701644828\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image # Import image processing module\n",
    "import matplotlib.pyplot as plt\n",
    "import torch # Import PyTorch library for deep learning\n",
    "import torchvision # Import TorchVision library for image processing\n",
    "\n",
    "# Define the preprocessing of image data.\n",
    "# Image data is converted into tensors.\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()])\n",
    "\n",
    "# Download training data and test data in MNIST dataset\n",
    "train_mnist = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_mnist = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define Dataloader which outputs for every 100 training data randomly.\n",
    "train_loader = torch.utils.data.DataLoader(train_mnist, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_mnist, batch_size=100, shuffle=True)\n",
    "\n",
    "# Define neural network\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, 3) # 28x28x1 -> 26x26x32 (CNN)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3) # 26x26x32 -> 24x24x64  (CNN)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2) # 24x24x64 -> 12x12x64 (Max Pooling)\n",
    "        self.fc1 = torch.nn.Linear(12 * 12 * 64, 128) # Fully-connected layer\n",
    "        self.fc2 = torch.nn.Linear(128, 10) # Fully-connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.nn.functional.relu(self.conv1(x)) # Apply the convolution process to the input data\n",
    "        h = torch.nn.functional.relu(self.conv2(h)) # Apply the convolution process to the hidden data\n",
    "        h = self.pool(h) # Apply max pooling to the hidden data\n",
    "        h = torch.flatten(h, start_dim=1) # Convert the tensor to a vector\n",
    "        h = torch.nn.functional.relu(self.fc1(h)) # Apply the fully-connected layer to the vector\n",
    "        y = self.fc2(h) # Apply the fully-connected layer to the hidden data\n",
    "        return y\n",
    "\n",
    "# Instantiate the defined neural network\n",
    "model = CNN()\n",
    "# Define a loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Define an optimizer which minimizes the loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Initialize the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Predict the target\n",
    "        outputs = model(inputs)\n",
    "        # Calculate the error between the prediction and the target\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Train the neural network\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if i == 0 or (i+1) % 100 == 0:\n",
    "            print('{0}, {1}, Loss:{2}'.format(epoch+1, i+1, total_loss/(i+1)))\n",
    "    print('Total loss:{}'.format(total_loss/(i+1)))\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128dd2f6",
   "metadata": {},
   "source": [
    "## Convolutional Layer\n",
    "In the convolutional layer, filters are used to extract local features from an image.\n",
    "Since the purpose of the filter is to capture only local features of the image, it is usually not set very large.\n",
    "Common sizes like 3x3 or 4x4 are often used.\n",
    "\n",
    "In the Convolution layer, a filter $h(i,j)$ is used to perform the following computation on a part of the image.\n",
    "$$ u'(x, y) = \\sum_i\\sum_j h(i, j) u(x+i, x+j)$$\n",
    "This operation is the element-wise product with the filter, $h(i,j)$ and a part of the image, and can be considered as a dot product.\n",
    "This means that this operation indicates the similarity between the filter and a part of the image.\n",
    "In other words, the convolution layer can be seen as a process that checks where the pattern represented by the filter exists on the image.\n",
    "\n",
    "This process involves scanning the input image from the top-left corner sequentially, processing the entire image.\n",
    "By adjusting the movement amount, it's possible to control how much image information is shared between the similarities calculated with the filter.\n",
    "This is specified as the \"stride\".\n",
    "\n",
    "Each filter represents one pattern.\n",
    "Therefore, if you want to detect multiple patterns from an image, such as straight lines, curves, and corners, you need to prepare multiple filters.\n",
    "Conceptually, each filter produces one \"channel\".\n",
    "Therefore, you need to specify the number of filters. Theoretically, the more filters you use, the more diverse patterns you can detect.\n",
    "\n",
    "````\n",
    "self.conv1 = torch.nn.Conv2d(1, 32, 3) # 28x28x1 -> 26x26x32 (CNN)\n",
    "````\n",
    "In this setting, the input information has one channel.\n",
    "By using 32 types of filters, it outputs 32 channels.\n",
    "The size of the filter is set to 3x3.\n",
    "While the stride is not explicitly mentioned, it defaults to 1, which means the filter processes the image by shifting one unit at a time.\n",
    "\n",
    "## Pooling Layer\n",
    "In image recognition, it's desirable to overlook minor rotations, translations, and scaling.\n",
    "For instance, in handwritten digits, the features identified by filters might slightly shift due to these variations.\n",
    "However, when making the final prediction, it's preferable to ignore such minute changes.\n",
    "In the pooling layer, to absorb such minor variations, a representative point is extracted from a predefined region, aiming to accommodate the aforementioned changes.\n",
    "\n",
    "The purpose of the pooling layer is to determine a value that represents the specified region.\n",
    "For this reason, common pooling methods include \"Max Pooling\" and \"Average Pooling\".\n",
    "Due to its simplicity in processing, many systems using CNNs frequently employ \"Max Pooling\".\n",
    "\n",
    "````\n",
    "self.pool = torch.nn.MaxPool2d(2, 2) # 24x24x64 -> 12x12x64 (Max Pooling)\n",
    "\n",
    "````\n",
    "In this setting, the maximum value is extracted from a 2x2 area for each channel.\n",
    "Since each channel contains a similarity measure of patterns extracted by the filters, even if there are minor changes within a 2x2 range, they will be absorbed through the processing of the pooling layer.\n",
    "\n",
    "## Classifier\n",
    "Using the features obtained from the convolutional and pooling layers, the Fully-connected layers are employed to make the final classification.\n",
    "The number of outputs matches the number of distinct categories to be classified, and the prediction is made based on the largest output value.\n",
    "\n",
    "## Training\n",
    "We have designed a CNN network.\n",
    "From here on, we will proceed with training using the training data.\n",
    "The basic flow involves defining a loss function to evaluate the discrepancy between the predictions and the actual values.\n",
    "The parameters (weights of the neural network), specifically the weights of the filters in the convolutional layer and the weights in the Fully-connected layer, are adjusted to minimize this loss function.\n",
    "\n",
    "### Loss function\n",
    "In this program, the error function is defined below.\n",
    "````\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "````\n",
    "Here, cross-entropy is used and defined as follows:\n",
    "$$ \\sum_i t_i \\log p_i $$\n",
    "${\\mathbf t}$ is a vector where only the correct values are 1, and ${\\mathbf p}$ represents the probability of the predicted values from the CNN network.\n",
    "However, the output ${\\mathbf o}$ from the CNN network is just a score, so to convert it to a probability, the following softmax function is used.\n",
    "$$ p_i = \\frac{e^{o_i}}{\\sum_i e^{o_i}}$$\n",
    "\n",
    "By differentiating this loss function with respect to the parameters, we can determine the gradient and seek the value that minimizes it.\n",
    "Using the chain rule of differentiation, the calculation of the gradient in the neural network can be expressed as a product form.\n",
    "This allows us to write the differentiation for each layer as a function, which is referred to as backpropagation.\n",
    "When writing this in an actual program, the gradient is computed using \"loss.backward()\", and corrections are made with \"optimizer.step()\".\n",
    "Specifically, for the update method, we use a state-of-the-art approach called Adam.\n",
    "\n",
    "# Assignment\n",
    "Using the CNN network created here, please classify the FashionMNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c663eb00",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (int, int, int), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_fashionmnist, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(test_fashionmnist, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mtrain_fashionmnist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (int, int, int), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image # Import image processing module\n",
    "import matplotlib.pyplot as plt\n",
    "import torch # Import PyTorch library for deep learning\n",
    "import torchvision # Import TorchVision library for image processing\n",
    "\n",
    "# Define the preprocessing of image data.\n",
    "# Image data is converted into tensors.\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()])\n",
    "\n",
    "# Download training data and test data in MNIST dataset\n",
    "train_fashionmnist = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_fashionmnist = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define Dataloader which outputs for every 100 training data randomly.\n",
    "train_loader = torch.utils.data.DataLoader(train_fashionmnist, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_fashionmnist, batch_size=100, shuffle=True)\n",
    "\n",
    "plt.imshow(train_fashionmnist[0][0].transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a66987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
