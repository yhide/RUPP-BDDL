{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ecb68de",
   "metadata": {},
   "source": [
    "# Big Data\n",
    "The difinition of big data is data that contains greater variety, arriving in increasing volumes and with velocity.\n",
    "\n",
    "In the Big Data analysis, due to the vast amount of data, it is not possible to process all the data on a computer.\n",
    "Based on this fact, when analyzing the data, it is important how to store and process the data.\n",
    "As for data storage, distributed databases become one of the solutions.\n",
    "In handling distributed databases, MapReduce is one of the methods.\n",
    "MapReduce consists of two main steps: \"map\" and \"reduce.\"\n",
    "The \"map\" step processes input data in each distributed database.\n",
    "The \"reduce\" step merges them to produce the final output.\n",
    "This framework allows for distributed processing of large data sets across multiple machines.\n",
    "By doing so, there is no need to gather all the data on a single server, allowing for the necessary processing to be carried out efficiently across multiple machines. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "307bfc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # import pandas module to process the dataset\n",
    "import matplotlib.pyplot as plt # import pyplot module to draw a graph\n",
    "\n",
    "# Read FIFA20 data\n",
    "player_df = pd.read_csv('./players_20.csv')\n",
    "\n",
    "index = [i for i in range(0, len(player_df), len(player_df)//3)]\n",
    "index[-1] = len(player_df)\n",
    "splited_player_df = []\n",
    "for start, end in zip(index[:-1], index[1:]):\n",
    "    splited_player_df.append(player_df[start:end])\n",
    "\n",
    "def search(df, nation):\n",
    "    return len(df.query('nationality==@nation'))\n",
    "\n",
    "print(sum([search(df, 'England') for df in splited_player_df]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4923640",
   "metadata": {},
   "source": [
    "When analyzing Big Data using machine learning, certain considerations must be made.\n",
    "Due to the sheer volume of the data, it's challenging to train on the entire dataset at once.\n",
    "Thus, the solution is to break the data into smaller chunks and handle it piecemeal.\n",
    "This approach is called mini-batch training.\n",
    "Additionally, if data arrives sequentially, there's a method called online learning where the model trains as new data becomes available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c441214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9456.942772732247\n",
      "9456.942772732282\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean([wage for wage in player_df['wage_eur']]))\n",
    "\n",
    "def online_mean(average, n, x):\n",
    "    return (average*n + x) / (n+1)\n",
    "\n",
    "average = 0\n",
    "for i, wage in enumerate(player_df['wage_eur']):\n",
    "    average = online_mean(average, i, wage)\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e355eca8",
   "metadata": {},
   "source": [
    "## Analysis Methods for Big Data Analysis\n",
    "1. Cross-tabulation\n",
    "2. Cluster analysis\n",
    "3. Association analysis\n",
    "4. Logistic regression analysis\n",
    "5. Decision tree analysis\n",
    "6. Pricipal component analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e44e4f",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "For each loop, generate nearly 1000 pieces of data using the generator().\n",
    "Please compute the average of the obtained data in an online learning format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c38c99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.99806126374199\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generator():\n",
    "    size = int(random.gauss(1000, 10))\n",
    "    return [random.uniform(0, 100) for _ in range(size)]\n",
    "    \n",
    "epochs = 100\n",
    "average = 0.0\n",
    "size = 0\n",
    "for _ in range(epochs):\n",
    "    data = generator()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
